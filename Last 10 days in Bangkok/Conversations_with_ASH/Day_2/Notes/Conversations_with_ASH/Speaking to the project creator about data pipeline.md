Lets break it into clear parts, even if they are just place holders.

1. Where the data is coming from, and how does it get on the blockchain - that workflow

2. How is that data, is located? what tools are used to search the description of the data on chain, and determine if its appropriate

3. Who is digesting and processing that data - how is it determined which blocks are 'good enough'

4. Once the blocks of data are selected, how is each one paid for, so that the data is collected as a total information bundle, and how is the unique data governance of each unit of data managed

5. How is the data of the data block accessed? When and where is it decrypted? How can the information be used, as part of a whole, without the risk of private information being revealed? What will constitute private information?

6. How is the data moved into a data template structure, to be fed into the AI?

7. How does the AI Consume this data in a systematic manner, and how does this data then get generated into a unique data product

8. How is that data product evaluated for quality?

9. What is the process through which that data product is stored and What is the process through which it is turned into a NFT data product?

10. How are the data history of the product retained, so that the 'creators' of that data paid for its use

11. What is the 'data market' and who is going to use it? How is it searched?

--------


The goal of this project is to design a MVP for the first part of the haunted house project. The goal of that project is to  create a a process through which localized information is transformed into to a format that allows it to be made into 'scary stories'.

